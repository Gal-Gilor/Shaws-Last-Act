{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shaw's Last Act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import string\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load text\n",
    "path = 'data/original_scripts.txt'\n",
    "path = os.path.join(path)\n",
    "\n",
    "with open(path, \"r\", encoding=\"utf8\") as line:\n",
    "    raw = line.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 95 unique characters in the text\n",
      "There are approximately 256334 words in the text\n",
      "There are approximately 45243 unique words in the text\n",
      "There are 31278 lines in the text\n",
      "On average, there are 8.195344970906069 words per line\n",
      "There are 8 different scripts in the text\n",
      "\n",
      "The text contains the scripts for the titles:\n",
      "  - Pygmalion\n",
      "  - Major Barbara\n",
      "  - Saint Joan\n",
      "  - Arms and the Man\n",
      "  - Man And Superman\n",
      "  - Mrs. Warrenâ€™s Profession\n",
      "  - Heartbreak House\n",
      "  - Caesar and Cleopatra\n"
     ]
    }
   ],
   "source": [
    "# text statatistics\n",
    "\n",
    "unique_chars = len(set(list(raw)))\n",
    "print(f'There are {unique_chars} unique characters in the text')\n",
    "\n",
    "n_words = len(raw.split(' '))\n",
    "print(f'There are approximately {n_words} words in the text')\n",
    "\n",
    "n_unique_words = len(set(raw.split(' ')))\n",
    "print(f'There are approximately {n_unique_words} unique words in the text')\n",
    "\n",
    "n_lines = len(raw.split('\\n'))\n",
    "print(f'There are {n_lines} lines in the text')\n",
    "\n",
    "print(f'On average, there are {n_words / n_lines} words per line')\n",
    "\n",
    "titles = re.findall('Title:.*\\n', raw)\n",
    "titles = [title.replace('\\n', '').replace('Title: ', '') for i, title in enumerate(titles)]\n",
    "print(f'There are {len(titles)} different scripts in the text\\n')\n",
    "print('The text contains the scripts for the titles:', *titles, sep='\\n  - ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify special characters to replace with word tokens\n",
    "special_characther = list(string.punctuation)\n",
    "pecial_characther.extend(['\\t', '\\n'])\n",
    "\n",
    "\n",
    "def create_lookup_tables(text):\n",
    "    '''\n",
    "    Create lookup tables and return a tuple of dicts (vocab_to_int, int_to_vocab)\n",
    "    inputs:\n",
    "        text: list, text split into words\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    char_set = tuple(set(text)) \n",
    "    int_to_vocab = dict(enumerate(char_set))\n",
    "    vocab_to_int = {char: i for i, char in int_to_vocab.items()}\n",
    "    \n",
    "    return (vocab_to_int, int_to_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch]",
   "language": "python",
   "name": "conda-env-torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
