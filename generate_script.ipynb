{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shaw's Last Act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as functional\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load text\n",
    "original_text_path = 'data/pygmalion.txt'\n",
    "with open(original_text_path, \"r\", encoding=\"utf8\") as line:\n",
    "    raw = line.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 77 unique characters in the text\n",
      "There are approximately 24955 words in the text\n",
      "There are approximately 5893 unique words in the text\n",
      "There are 2161 lines in the text\n",
      "On average, there are 11.547894493290144 words per line\n"
     ]
    }
   ],
   "source": [
    "# text statatistics\n",
    "\n",
    "unique_chars = set(list(raw))\n",
    "print(f'There are {len(unique_chars)} unique characters in the text')\n",
    "\n",
    "n_words = len(raw.split(' '))\n",
    "print(f'There are approximately {n_words} words in the text')\n",
    "\n",
    "n_unique_words = len(set(raw.split(' ')))\n",
    "print(f'There are approximately {n_unique_words} unique words in the text')\n",
    "\n",
    "n_lines = len(raw.split('\\n'))\n",
    "print(f'There are {n_lines} lines in the text')\n",
    "\n",
    "print(f'On average, there are {n_words / n_lines} words per line')\n",
    "\n",
    "# titles = re.findall('Title:.*\\n', raw)\n",
    "# titles = [title.replace('\\n', '').replace('Title: ', '') for i, title in enumerate(titles)]\n",
    "# print(f'There are {len(titles)} different scripts in the text\\n')\n",
    "# print('The text contains the scripts for the titles:', *titles, sep='\\n  - ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess raw text\n",
    "def text_special_characters(text):\n",
    "\n",
    "    # identify all unique characters\n",
    "    unique_chars = list(set(list(text)))\n",
    "    \n",
    "    # merge the characters to a single string\n",
    "    unique_chars = ''.join(unique_chars)\n",
    "    \n",
    "    # remove letters and spaces \n",
    "    unique_chars = re.sub('[a-zA-Z\\s+:]', '', unique_chars)\n",
    "    \n",
    "    return unique_chars\n",
    "\n",
    "def special_characters_json(filepath):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    with open(filepath, encoding='utf8') as line:\n",
    "        char2token = json.loads(line.read())\n",
    "        \n",
    "    token2char = {special: token for token, special in char2token.items()}\n",
    "    return (char2token, token2char)\n",
    "\n",
    "# tokenize special characters\n",
    "def tokenize_special_characters(text):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    # load the special characters to tokenize\n",
    "    special2token, _ = special_characters_json('character_dictionary.json')\n",
    "\n",
    "    # replace special characters with the new tokens\n",
    "    for special, token in special2token.items():\n",
    "        text = text.replace(special, f' {token} ')\n",
    "    \n",
    "    # replace multiple whitespaces with single whitespace\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "text = tokenize_special_characters(raw)\n",
    "\n",
    "path_tokenized = 'data/tokenized_script.txt'\n",
    "with open(path_tokenized, \"w\") as line:\n",
    "    line.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using: {DEVICE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "class ShawsDataset(Dataset):\n",
    "    '''\n",
    "    Creates a custom PyTorch Dataset class\n",
    "    args:\n",
    "        filepath: string, path to text (UTF8)\n",
    "        sequence_length: integer, sequence length\n",
    "    '''\n",
    "\n",
    "    def __init__(self, filepath, sequence_length):\n",
    "        self.filepath = filepath\n",
    "        self.sequence_length = sequence_length\n",
    "        \n",
    "        self.words = self.load_text() \n",
    "        \n",
    "        self.word_to_index, self.index_to_word = self.proccess_text()        \n",
    "        self.words_indexes = [self.word_to_index[w] for w in self.words]\n",
    "\n",
    "    def load_text(self):\n",
    "        with open(self.filepath, \"r\", encoding='utf8') as line:  # , encoding='utf8'\n",
    "            text = line.read()\n",
    "        return text.split()\n",
    "\n",
    "    def proccess_text(self):\n",
    "        words = self.words\n",
    "        vocab = Counter(words)\n",
    "        vocab = sorted(vocab, key=vocab.get, reverse=True)\n",
    "        \n",
    "        word_to_index, index_to_word = {}, {}\n",
    "        for i, w in enumerate(vocab + ['<PAD>']):\n",
    "            word_to_index[w] = i\n",
    "            index_to_word[i] = w\n",
    "        \n",
    "        return (word_to_index, index_to_word)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.words_indexes) - self.sequence_length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (\n",
    "            torch.tensor(\n",
    "                self.words_indexes[index: index+self.sequence_length]),\n",
    "            torch.tensor(self.words_indexes[index+self.sequence_length]),\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class ShawsLSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, dropout=0.5):\n",
    "        '''\n",
    "        Initialize the PyTorch RNN Module\n",
    "        inputs:\n",
    "            vocab_size: integer, number of input dimensions (the size of the vocabulary)\n",
    "            output_size: integer, number of output dimensions (the size of the vocabulary)\n",
    "            embedding_dim: integer, word embedding dimensions       \n",
    "            hidden_dim: integer, number hidden layer output nodes\n",
    "            dropout: float, range between 0 and 1 to describe the chance of LSTM dropout layer (default= 0.5)\n",
    "        '''\n",
    "        super(ShawsLSTM, self).__init__()\n",
    "        \n",
    "        # init hidden weights params\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "        # define the embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # define the LSTM layer\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, \n",
    "                            dropout=dropout, batch_first=True)\n",
    "\n",
    "        # define fully-connected layer\n",
    "        self.dense = nn.Linear(hidden_dim, output_size)\n",
    "    \n",
    "    \n",
    "    def forward(self, nn_input, hidden):\n",
    "        '''\n",
    "        Returns the model output and the latest hidden state as Tensors\n",
    "        inputs:\n",
    "           nn_input: model inputs\n",
    "           hidden: the last hideen state        \n",
    "        '''\n",
    "        assert hasattr(self, \"batch_size\"), 'Initalize hidden weights first! -> init_hidden(batch_size)'\n",
    "        \n",
    "        # ensure embedding layer gets a LongTensor input\n",
    "        nn_input = nn_input.long()\n",
    "        \n",
    "        ## define forward pass\n",
    "        embed = self.embedding(nn_input)\n",
    "        output, state = self.lstm(embed, hidden)\n",
    "        \n",
    "        # stack LSTM\n",
    "        output = output.contiguous().view(-1, self.hidden_dim) \n",
    "        \n",
    "        # pass through last fully connected layer\n",
    "        output = self.dense(output)\n",
    "        \n",
    "        output = output.view(self.batch_size, -1, self.vocab_size)\n",
    "        output = output[:, -1] # save only the last output\n",
    "        \n",
    "        # return one batch of output word scores and the hidden state\n",
    "        return output, state   \n",
    "\n",
    "    \n",
    "    def init_hidden(self, batch_size, device):\n",
    "        '''\n",
    "        Initialize the hidden state of an LSTM in the shape (n_layers, batch_size, hidden_dim)\n",
    "        inputs:\n",
    "            batch_size: integer, the batch_size of the hidden state\n",
    "        \n",
    "        '''\n",
    "       \n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters()).data\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # reshape, zero, and move to device\n",
    "        hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device),\n",
    "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device))\n",
    "        \n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backpropagation(rnn, optimizer, criterion, inputs, target, hidden, device):\n",
    "    '''\n",
    "    Completes the forward and backward propagation, and \n",
    "    returns the final hidden state and train loss\n",
    "        rnn: ShawsLSTM instance, PyTorch class\n",
    "        optimizer: torch.optim, PyTorch optimizer\n",
    "        criterion: loss function class, PyTorch (or custom) loss function\n",
    "        inputs: torch Tensor, a batch of input to the neural network\n",
    "        target: torch Tensor, the target output for the batch of inputs\n",
    "    '''\n",
    "    \n",
    "    # move model to GPU, if available\n",
    "    rnn.to(device)\n",
    "    \n",
    "    # move data to GPU, if available\n",
    "    inputs, target = inputs.to(device), target.to(device)\n",
    "    \n",
    "    # dismember the hidden states to prevent backprop through entire training history\n",
    "    hidden = tuple([hid.data for hid in hidden])\n",
    "    \n",
    "    # zero accumulated gradients\n",
    "    rnn.zero_grad()\n",
    "\n",
    "    # get the output and hidden state from the model\n",
    "    output, hidden = rnn(inputs, hidden)\n",
    "    \n",
    "    # calcualte the loss\n",
    "    loss = criterion(output.squeeze(), target.long())\n",
    "    \n",
    "    # perform backpropagation\n",
    "    loss.backward()\n",
    "    \n",
    "    # clip to prevent gradients from becoming too large before optimizating\n",
    "    nn.utils.clip_grad_value_(rnn.parameters(), 4)\n",
    "    optimizer.step()\n",
    "    \n",
    "    # ensure everything is sent back to cpu\n",
    "    rnn.to(torch.device('cpu'))\n",
    "    inputs, target = inputs.to(torch.device('cpu')), target.to(torch.device('cpu'))\n",
    "    \n",
    "    # return the loss over a batch and the hidden state produced by our model\n",
    "    return loss.item(), hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_rnn(rnn, batch_size, optimizer, criterion, n_epochs, device, show_every_n_batches=100):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    batch_losses = []\n",
    "    rnn.train()\n",
    "    print(\"Training for %d epoch(s)...\" % n_epochs)\n",
    "    for epoch_i in tqdm(range(1, n_epochs + 1)):\n",
    "\n",
    "\n",
    "        # initialize hidden state\n",
    "        hidden = rnn.init_hidden(batch_size, device)\n",
    "\n",
    "        for batch_i, (inputs, labels) in enumerate(train_loader, 1):\n",
    "\n",
    "            # make sure you iterate over completely full batches, only\n",
    "            n_batches = len(train_loader.dataset)//batch_size\n",
    "            if(batch_i > n_batches):\n",
    "                break\n",
    "\n",
    "            # forward, back prop\n",
    "            loss, hidden = forward_back_prop(rnn, optimizer, criterion, inputs, labels, hidden)          \n",
    "            # record loss\n",
    "            batch_losses.append(loss)\n",
    "\n",
    "            # printing loss stats\n",
    "            if batch_i % show_every_n_batches == 0:\n",
    "                print(f'Epoch: {epoch_i}/{n_epochs}  Loss: {np.average(batch_losses)}\\n')\n",
    "                batch_losses = []\n",
    "\n",
    "    # returns a trained rnn\n",
    "    return rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data parameters\n",
    "BATCH_SIZE = 64\n",
    "SEQUENCE_LENGTH = 12\n",
    "\n",
    "dataset = ShawsDataset('data/pygmalion.txt', SEQUENCE_LENGTH)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training parameters\n",
    "EPOCHS = 2 #\n",
    "LEARNING_RATE = 0.0005 # 0.001 0.002\n",
    "\n",
    "# model parameters\n",
    "VOCAB_SIZE = len(dataset.word_to_index)\n",
    "OUTPUT_SIZE = VOCAB_SIZE\n",
    "EMBEDDINGS = 200 # 300\n",
    "HIDDEN_DIM = 256\n",
    "N_LAYERS = 2 \n",
    "\n",
    "# show stats for every n number of batches\n",
    "SHOW_EVERY = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 2 epoch(s)...\n",
      "\n",
      "Epoch: 1/2  Loss: 7.910517921447754\n",
      "Epoch: 1/2  Loss: 7.3547390174865725\n",
      "Epoch: 1/2  Loss: 7.106177129745483\n",
      "Epoch: 1/2  Loss: 7.1286507511138915\n"
     ]
    }
   ],
   "source": [
    "# create modl\n",
    "model = ShawsLSTM(VOCAB_SIZE, OUTPUT_SIZE, EMBEDDINGS, HIDDEN_DIM, N_LAYERS)\n",
    "\n",
    "# defining loss and optimization functions for training\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# train model \n",
    "batch_losses = []\n",
    "model.train()\n",
    "print(f\"Training for {EPOCHS} epoch(s)...\\n\")\n",
    "for epoch_i in tqdm(range(1, EPOCHS + 1)):\n",
    "\n",
    "    # initialize hidden state\n",
    "    hidden = model.init_hidden(BATCH_SIZE, DEVICE)\n",
    "\n",
    "    for batch_i, (inputs, labels) in enumerate(dataloader, 1):\n",
    "\n",
    "        # make sure you iterate over completely full batches, only\n",
    "        n_batches = len(dataloader.dataset)//BATCH_SIZE\n",
    "        if(batch_i > n_batches):\n",
    "            break\n",
    "\n",
    "        # forward, back prop\n",
    "        loss, hidden = backpropagation(model, optimizer, criterion, inputs, labels, hidden, DEVICE)          \n",
    "        \n",
    "        # record loss\n",
    "        batch_losses.append(loss)\n",
    "\n",
    "        # printing loss stats\n",
    "        if batch_i % SHOW_EVERY == 0:\n",
    "            print(f'Epoch: {epoch_i}/{EPOCHS}  Loss: {np.average(batch_losses)}')\n",
    "            batch_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import Dataset\n",
    "# from collections import Counter\n",
    "# from gensim.utils import tokenize\n",
    "# from gensim.corpora.dictionary import Dictionary\n",
    "\n",
    "# class Test(Dataset):\n",
    "#     '''\n",
    "#     Creates a custom PyTorch Dataset class\n",
    "#     args:\n",
    "#         filepath: string, path to text (UTF8)\n",
    "#         sequence_length: integer, sequence length\n",
    "#     '''\n",
    "#     def __init__(self, filepath, sequence_length):\n",
    "#         super(Test, self).__init__()\n",
    "#         self.filepath = filepath\n",
    "#         self.sequence_length = sequence_length\n",
    "        \n",
    "#         self.words = self.load_text()        \n",
    "#         self.tokens = list(tokenize(self.words, token_pattern='\\S+'))\n",
    "#         self.token_dict = Dictionary([self.tokens])\n",
    "        \n",
    "#         self.words_indexes = [self.token_dict.token2id[token] for token in self.tokens]\n",
    "    \n",
    "#     def load_text(self):\n",
    "#         with open(self.filepath, \"r\") as line:\n",
    "#             text = line.read()\n",
    "            \n",
    "#         # replace multiple whitespaces with single whitespace\n",
    "#         text = re.sub(r\"\\s+\", \" \", text)\n",
    "#         return text\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.words_indexes) - self.sequence_length\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#         return (\n",
    "#             torch.tensor(self.words_indexes[index : index+self.sequence_length]),\n",
    "#             torch.tensor(self.words_indexes[index+self.sequence_length]),\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_special_characters(text):\n",
    "\n",
    "    # identify all unique characters\n",
    "    unique_chars = list(set(list(text)))\n",
    "    \n",
    "    # merge the characters to a single string\n",
    "    unique_chars = ''.join(unique_chars)\n",
    "    \n",
    "    # remove letters and spaces \n",
    "    unique_chars = re.sub('[a-zA-Z\\s:]', '', unique_chars)\n",
    "    \n",
    "    return unique_chars\n",
    "\n",
    "a = text_special_characters(raw)\n",
    "\n",
    "dict(enumerate(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch]",
   "language": "python",
   "name": "conda-env-torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
